{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FraudDetectioin.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCvnYBhA3j-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13618fc5-73c5-41f8-c969-52a5829e24f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi3ORUB5ozA3"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73nTCnG0o74F"
      },
      "source": [
        "##Import libraris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97KceU6m4qfL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twiv1TjupKHL"
      },
      "source": [
        "##Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IECIn0ku4CsF"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/Fraud Detection/Proj3.zip' -d '/content/drive/MyDrive/Fraud Detection/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di8LuwJk5_9E"
      },
      "source": [
        "test_identity = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/test_identity.csv\")\n",
        "train_identity = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/train_identity.csv\")\n",
        "test_transaction = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/test_transaction.csv\")\n",
        "train_transaction = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/train_transaction.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_iNneJMpUX4"
      },
      "source": [
        "##Remove columns full of null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XL32CDutAi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a044df4-5d4e-42b4-d187-a9b48bdc4d87"
      },
      "source": [
        "for col in train_transaction.columns:\n",
        "  print(train_transaction[col].isna().sum())\n",
        "  if train_transaction[col].isna().sum() > 400000:\n",
        "    train_transaction.drop(labels=[col], axis=1, inplace=True)\n",
        "    test_transaction.drop(labels=[col], axis=1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "8933\n",
            "1565\n",
            "1577\n",
            "4259\n",
            "1571\n",
            "65706\n",
            "65706\n",
            "352271\n",
            "552913\n",
            "94456\n",
            "453249\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1269\n",
            "280797\n",
            "262878\n",
            "168922\n",
            "309841\n",
            "517353\n",
            "551623\n",
            "515614\n",
            "515614\n",
            "76022\n",
            "279287\n",
            "525823\n",
            "528588\n",
            "528353\n",
            "89113\n",
            "271100\n",
            "271100\n",
            "271100\n",
            "281444\n",
            "350482\n",
            "169360\n",
            "346265\n",
            "346252\n",
            "346252\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "279287\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "76073\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "168969\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "77096\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "89164\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "314\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508589\n",
            "508589\n",
            "508589\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508589\n",
            "508589\n",
            "508589\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508589\n",
            "508589\n",
            "508595\n",
            "508595\n",
            "508595\n",
            "508589\n",
            "508589\n",
            "508589\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450721\n",
            "450721\n",
            "450721\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "450909\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "449124\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "449124\n",
            "449124\n",
            "449124\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "460110\n",
            "12\n",
            "12\n",
            "1269\n",
            "1269\n",
            "1269\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "1269\n",
            "1269\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "1269\n",
            "12\n",
            "12\n",
            "12\n",
            "1269\n",
            "1269\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "1269\n",
            "1269\n",
            "1269\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n",
            "508189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46P874Q0GZkH"
      },
      "source": [
        "for i, col in enumerate(train_identity.columns):\n",
        "  if train_identity[col].isna().sum() > 65000:\n",
        "    test_identity.drop([col.replace(\"_\",\"-\")], inplace=True, axis=1)\n",
        "    train_identity.drop([col], inplace=True, axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbsQSJysplfe"
      },
      "source": [
        "##Save Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNfGP-mMyh6T"
      },
      "source": [
        "train_transaction.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_train_transaction.csv\")\n",
        "test_transaction.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_test_transaction.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxVP2TYH6oCb"
      },
      "source": [
        "train_identity.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_train_identity.csv\")\n",
        "test_identity.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_test_identity.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0t6CKfqpyVR"
      },
      "source": [
        "##Import not null datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh6mZWrNztpC"
      },
      "source": [
        "train_transaction = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_train_transaction.csv\")\n",
        "train_transaction.drop(labels=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "test_transaction = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_test_transaction.csv\")\n",
        "test_transaction.drop(labels=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "train_identity = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_train_identity.csv\")\n",
        "train_identity.drop(labels=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "test_identity = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/not_null_test_identity.csv\")\n",
        "test_identity.drop(labels=[\"Unnamed: 0\"], axis=1, inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otICY6m9p6iC"
      },
      "source": [
        "##Merge transaction and identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUaQx07l8g1P"
      },
      "source": [
        "train = pd.merge(train_transaction, train_identity, on=\"TransactionID\")\n",
        "test = pd.merge(test_transaction, test_identity, on=\"TransactionID\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUniGJEqqC8p"
      },
      "source": [
        "##Remove null columns from merged dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0iJYMLBmLPk"
      },
      "source": [
        "for i in train.columns:\n",
        "  if train[i].isna().sum() > 70000:\n",
        "      train.drop([i], inplace=True, axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432lmwe9qL-d"
      },
      "source": [
        "##Find categorical columns \n",
        "and remove categorical columns with many classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0stgEGUHuOQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8fc0cf-add6-42a2-f384-6b40b734e79d"
      },
      "source": [
        "one_hot = []\n",
        "for i in train.columns:\n",
        "  if i == 'isFraud':\n",
        "    continue\n",
        "  if len(np.unique(train[i].astype(str))) == 1:\n",
        "    train.drop([i], inplace=True, axis=1)\n",
        "    continue\n",
        "  print(i)\n",
        "  if all(isinstance(x, int) or isinstance(x, float) for x in train[i]):\n",
        "    print('int')\n",
        "    if len(np.unique(train[i].astype(str))) <= 5:\n",
        "      print(len(np.unique(train[i].astype(str))))\n",
        "      print('categorical int')\n",
        "      one_hot.append(i)\n",
        "  else:\n",
        "    if len(np.unique(train[i].astype(str))) <= 5:\n",
        "      print(len(np.unique(train[i].astype(str))))\n",
        "      print('categorical string')\n",
        "      one_hot.append(i)\n",
        "    else:\n",
        "      train.drop([i], inplace=True, axis=1)\n",
        "  print(\"-----\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransactionID\n",
            "int\n",
            "-----\n",
            "TransactionDT\n",
            "int\n",
            "-----\n",
            "TransactionAmt\n",
            "int\n",
            "-----\n",
            "ProductCD\n",
            "4\n",
            "categorical string\n",
            "-----\n",
            "card1\n",
            "int\n",
            "-----\n",
            "card2\n",
            "int\n",
            "-----\n",
            "card3\n",
            "int\n",
            "-----\n",
            "card4\n",
            "5\n",
            "categorical string\n",
            "-----\n",
            "card5\n",
            "int\n",
            "-----\n",
            "card6\n",
            "4\n",
            "categorical string\n",
            "-----\n",
            "addr1\n",
            "int\n",
            "-----\n",
            "addr2\n",
            "int\n",
            "-----\n",
            "P_emaildomain\n",
            "-----\n",
            "C1\n",
            "int\n",
            "-----\n",
            "C2\n",
            "int\n",
            "-----\n",
            "C3\n",
            "int\n",
            "-----\n",
            "C4\n",
            "int\n",
            "-----\n",
            "C6\n",
            "int\n",
            "-----\n",
            "C7\n",
            "int\n",
            "-----\n",
            "C8\n",
            "int\n",
            "-----\n",
            "C10\n",
            "int\n",
            "-----\n",
            "C11\n",
            "int\n",
            "-----\n",
            "C12\n",
            "int\n",
            "-----\n",
            "C13\n",
            "int\n",
            "-----\n",
            "C14\n",
            "int\n",
            "-----\n",
            "D1\n",
            "int\n",
            "-----\n",
            "V95\n",
            "int\n",
            "-----\n",
            "V96\n",
            "int\n",
            "-----\n",
            "V97\n",
            "int\n",
            "-----\n",
            "V98\n",
            "int\n",
            "-----\n",
            "V99\n",
            "int\n",
            "-----\n",
            "V100\n",
            "int\n",
            "-----\n",
            "V101\n",
            "int\n",
            "-----\n",
            "V102\n",
            "int\n",
            "-----\n",
            "V103\n",
            "int\n",
            "-----\n",
            "V104\n",
            "int\n",
            "-----\n",
            "V105\n",
            "int\n",
            "-----\n",
            "V106\n",
            "int\n",
            "-----\n",
            "V107\n",
            "int\n",
            "2\n",
            "categorical int\n",
            "-----\n",
            "V108\n",
            "int\n",
            "-----\n",
            "V109\n",
            "int\n",
            "-----\n",
            "V110\n",
            "int\n",
            "-----\n",
            "V111\n",
            "int\n",
            "-----\n",
            "V112\n",
            "int\n",
            "-----\n",
            "V113\n",
            "int\n",
            "-----\n",
            "V114\n",
            "int\n",
            "-----\n",
            "V115\n",
            "int\n",
            "-----\n",
            "V116\n",
            "int\n",
            "-----\n",
            "V117\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V118\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V119\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V120\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V121\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V122\n",
            "int\n",
            "5\n",
            "categorical int\n",
            "-----\n",
            "V123\n",
            "int\n",
            "-----\n",
            "V124\n",
            "int\n",
            "-----\n",
            "V125\n",
            "int\n",
            "-----\n",
            "V126\n",
            "int\n",
            "-----\n",
            "V127\n",
            "int\n",
            "-----\n",
            "V128\n",
            "int\n",
            "-----\n",
            "V129\n",
            "int\n",
            "-----\n",
            "V130\n",
            "int\n",
            "-----\n",
            "V131\n",
            "int\n",
            "-----\n",
            "V132\n",
            "int\n",
            "-----\n",
            "V133\n",
            "int\n",
            "-----\n",
            "V134\n",
            "int\n",
            "-----\n",
            "V135\n",
            "int\n",
            "-----\n",
            "V136\n",
            "int\n",
            "-----\n",
            "V137\n",
            "int\n",
            "-----\n",
            "V279\n",
            "int\n",
            "-----\n",
            "V280\n",
            "int\n",
            "-----\n",
            "V281\n",
            "int\n",
            "-----\n",
            "V282\n",
            "int\n",
            "-----\n",
            "V283\n",
            "int\n",
            "-----\n",
            "V284\n",
            "int\n",
            "-----\n",
            "V285\n",
            "int\n",
            "-----\n",
            "V286\n",
            "int\n",
            "-----\n",
            "V287\n",
            "int\n",
            "-----\n",
            "V288\n",
            "int\n",
            "-----\n",
            "V289\n",
            "int\n",
            "-----\n",
            "V290\n",
            "int\n",
            "-----\n",
            "V291\n",
            "int\n",
            "-----\n",
            "V292\n",
            "int\n",
            "-----\n",
            "V293\n",
            "int\n",
            "-----\n",
            "V294\n",
            "int\n",
            "-----\n",
            "V295\n",
            "int\n",
            "-----\n",
            "V296\n",
            "int\n",
            "-----\n",
            "V297\n",
            "int\n",
            "-----\n",
            "V298\n",
            "int\n",
            "-----\n",
            "V299\n",
            "int\n",
            "-----\n",
            "V300\n",
            "int\n",
            "-----\n",
            "V301\n",
            "int\n",
            "-----\n",
            "V302\n",
            "int\n",
            "-----\n",
            "V303\n",
            "int\n",
            "-----\n",
            "V304\n",
            "int\n",
            "-----\n",
            "V305\n",
            "int\n",
            "2\n",
            "categorical int\n",
            "-----\n",
            "V306\n",
            "int\n",
            "-----\n",
            "V307\n",
            "int\n",
            "-----\n",
            "V308\n",
            "int\n",
            "-----\n",
            "V309\n",
            "int\n",
            "-----\n",
            "V310\n",
            "int\n",
            "-----\n",
            "V311\n",
            "int\n",
            "-----\n",
            "V312\n",
            "int\n",
            "-----\n",
            "V313\n",
            "int\n",
            "-----\n",
            "V314\n",
            "int\n",
            "-----\n",
            "V315\n",
            "int\n",
            "-----\n",
            "V316\n",
            "int\n",
            "-----\n",
            "V317\n",
            "int\n",
            "-----\n",
            "V318\n",
            "int\n",
            "-----\n",
            "V319\n",
            "int\n",
            "-----\n",
            "V320\n",
            "int\n",
            "-----\n",
            "V321\n",
            "int\n",
            "-----\n",
            "id_01\n",
            "int\n",
            "-----\n",
            "id_02\n",
            "int\n",
            "-----\n",
            "id_05\n",
            "int\n",
            "-----\n",
            "id_06\n",
            "int\n",
            "-----\n",
            "id_11\n",
            "int\n",
            "-----\n",
            "id_12\n",
            "2\n",
            "categorical string\n",
            "-----\n",
            "id_13\n",
            "int\n",
            "-----\n",
            "id_14\n",
            "int\n",
            "-----\n",
            "id_15\n",
            "4\n",
            "categorical string\n",
            "-----\n",
            "id_16\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_17\n",
            "int\n",
            "-----\n",
            "id_19\n",
            "int\n",
            "-----\n",
            "id_20\n",
            "int\n",
            "-----\n",
            "id_28\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_29\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_31\n",
            "-----\n",
            "id_35\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_36\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_37\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "id_38\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "DeviceType\n",
            "3\n",
            "categorical string\n",
            "-----\n",
            "DeviceInfo\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KcHPrEEqwpK"
      },
      "source": [
        "##Encode categorical columns with one hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3QOINQe3812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868a4f5a-44d6-4eb8-b504-5a27a67382a7"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "new_train = np.array(train)\n",
        "for col in one_hot:\n",
        "  data = train[col].astype(str)\n",
        "  values = np.array(data)\n",
        "  print(values)\n",
        "  # integer encodefrom keras.utils import to_cate\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  integer_encoded = label_encoder.fit_transform(values)\n",
        "  print(integer_encoded)\n",
        "  # binary encode\n",
        "  onehot_encoder = OneHotEncoder(sparse=False)\n",
        "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "  onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "  print(onehot_encoded)\n",
        "  new_train = np.concatenate((new_train,onehot_encoded), axis =1)\n",
        "  print(new_train.shape)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H' 'H' 'C' ... 'C' 'R' 'C']\n",
            "[1 1 0 ... 0 2 0]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "(144233, 136)\n",
            "['mastercard' 'visa' 'mastercard' ... 'mastercard' 'visa' 'mastercard']\n",
            "[2 4 2 ... 2 4 2]\n",
            "[[0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]]\n",
            "(144233, 141)\n",
            "['credit' 'debit' 'credit' ... 'credit' 'credit' 'debit']\n",
            "[1 2 1 ... 1 1 2]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]]\n",
            "(144233, 145)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "(144233, 147)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 152)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 157)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 162)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 167)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 172)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(144233, 177)\n",
            "['1.0' '1.0' '1.0' ... '1.0' '1.0' '1.0']\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "(144233, 179)\n",
            "['NotFound' 'NotFound' 'NotFound' ... 'NotFound' 'NotFound' 'NotFound']\n",
            "[1 1 1 ... 1 1 1]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "(144233, 181)\n",
            "['New' 'New' 'Found' ... 'New' 'Found' 'New']\n",
            "[1 1 0 ... 1 0 1]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "(144233, 185)\n",
            "['NotFound' 'NotFound' 'Found' ... 'NotFound' 'Found' 'NotFound']\n",
            "[1 1 0 ... 1 0 1]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "(144233, 188)\n",
            "['New' 'New' 'Found' ... 'New' 'Found' 'New']\n",
            "[1 1 0 ... 1 0 1]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "(144233, 191)\n",
            "['NotFound' 'NotFound' 'Found' ... 'NotFound' 'Found' 'NotFound']\n",
            "[1 1 0 ... 1 0 1]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "(144233, 194)\n",
            "['T' 'T' 'F' ... 'F' 'T' 'F']\n",
            "[1 1 0 ... 0 1 0]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "(144233, 197)\n",
            "['F' 'F' 'F' ... 'F' 'F' 'F']\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "(144233, 200)\n",
            "['T' 'F' 'T' ... 'T' 'T' 'T']\n",
            "[1 0 1 ... 1 1 1]\n",
            "[[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "(144233, 203)\n",
            "['T' 'T' 'T' ... 'F' 'F' 'F']\n",
            "[1 1 1 ... 0 0 0]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "(144233, 206)\n",
            "['mobile' 'mobile' 'desktop' ... 'mobile' 'desktop' 'mobile']\n",
            "[1 1 0 ... 1 0 1]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n",
            "(144233, 209)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7q-Ly393Lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68b330f-949d-4aab-9a3f-d87adced4881"
      },
      "source": [
        "sparse = []\n",
        "print(new_train.shape)\n",
        "for i in new_train:\n",
        "  sparse.append(i[132:])\n",
        "np.array(sparse).shape\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144233, 209)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 77)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHQnL5-iu7Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd516835-4ab5-4564-e8fa-62a67b9706b4"
      },
      "source": [
        "train.drop(labels=one_hot, axis=1, inplace=True)\n",
        "train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 111)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJyitM_LrD1l"
      },
      "source": [
        "##Drop Transactio Id column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPSVjrDZON79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cc7922-2d12-4b7f-c6af-dfcbeab7f4de"
      },
      "source": [
        "train.drop(['TransactionID'], axis=1, inplace=True)\n",
        "train = np.concatenate((np.array(train),np.array(sparse)), axis=1)\n",
        "\n",
        "train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw4aLM6TrLVW"
      },
      "source": [
        "##Split fraud and normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k8K-MCbOn6Y"
      },
      "source": [
        "normal = []\n",
        "fraud = []\n",
        "for i in train:\n",
        "  if i[0] == 0:\n",
        "    normal.append(i)\n",
        "  else:\n",
        "    fraud.append(i)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmG3iIDQrap8"
      },
      "source": [
        "##Remove isFraud column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhaW1QwCRdex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee67d74-1399-42c0-9b0f-82a6b28d8a44"
      },
      "source": [
        "new_normal = []\n",
        "for i in normal:\n",
        "  new_normal.append(i[1:])\n",
        "new_fraud = []\n",
        "for i in fraud:\n",
        "  new_fraud.append(i[1:])\n",
        "print(np.array(new_normal).shape)\n",
        "print(np.array(new_fraud).shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132915, 186)\n",
            "(11318, 186)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmRVp7jpSDoe"
      },
      "source": [
        "X = pd.DataFrame(new_normal)\n",
        "fraud_x = pd.DataFrame(new_fraud)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VmO6HkWrl85"
      },
      "source": [
        "##Save Fraud and Normal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUEMtaalWCsH"
      },
      "source": [
        "X.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/X.csv\")\n",
        "fraud_x.to_csv(\"./drive/MyDrive/Fraud Detection/Proj3/fraud_x.csv\")\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ_0_jdTTjgO"
      },
      "source": [
        "normal = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/X.csv\")\n",
        "fraud = pd.read_csv(\"./drive/MyDrive/Fraud Detection/Proj3/fraud_x.csv\")\n",
        "normal.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "fraud.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL1hJVo9ryq_"
      },
      "source": [
        "##Fill null values with avrage of column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk_Y75mlr28x"
      },
      "source": [
        "###find avrage of each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsYx9Pb3XRiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386416fb-c434-40c3-f91e-f408c4f69d06"
      },
      "source": [
        "values = {}\n",
        "for i in normal.columns:\n",
        "  print(normal[i].isna().sum())\n",
        "  print(type(normal[i]))\n",
        "  values[i] = np.mean(normal[i])\n",
        "  print(values[i])\n",
        "  print(\"-------\")\n",
        "\n",
        "fraud_values = {}\n",
        "for i in fraud.columns:\n",
        "  print(fraud[i].isna().sum())\n",
        "  print(type(fraud[i]))\n",
        "  fraud_values[i] = np.mean(fraud[i])\n",
        "  print(fraud_values[i])\n",
        "  print(\"-------\")\n",
        "\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "6041497.576247978\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "83.10698908325327\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "9929.935770981454\n",
            "-------\n",
            "664\n",
            "<class 'pandas.core.series.Series'>\n",
            "394.021557492949\n",
            "-------\n",
            "160\n",
            "<class 'pandas.core.series.Series'>\n",
            "160.85456668298747\n",
            "-------\n",
            "890\n",
            "<class 'pandas.core.series.Series'>\n",
            "191.79369816322665\n",
            "-------\n",
            "53014\n",
            "<class 'pandas.core.series.Series'>\n",
            "296.80656061876573\n",
            "-------\n",
            "53014\n",
            "<class 'pandas.core.series.Series'>\n",
            "86.25260009261461\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "25.284053718541927\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "30.917202723545124\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.024955798818793964\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "14.710627092502728\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "14.686867546928488\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "9.668607756837076\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "17.933935221758265\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "18.62448933528947\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "18.846683970958882\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "13.37867057894143\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "19.88336154685325\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "10.129541436256254\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "30.50740645861274\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "3.8246221472872883\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "8.00229571867285\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "5.632828024327091\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.03317878003251641\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4723685795146625\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.16615734328897452\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "3.591128740892395\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "6.7337719034142225\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "4.997756969952429\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.19533931474679353\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.7895691575841512\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.46323086650207745\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0024838923345578\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0028828204973805\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0026344312639248\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0029806708014692\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0032516408743302\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0031387366773048\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0074742578430782\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0093334136207623\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0082570602757872\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0373562353224544\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.073282350815921\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0581908231468657\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "437.9130654497475\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "838.2408447390428\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "617.7026374538043\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "5.559718625053935\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "35.16303519392714\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "16.43970266029938\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "398.6760181799121\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "710.1331237910259\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "539.0232228456415\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "31.80973192094723\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "89.8423762584645\n",
            "-------\n",
            "59\n",
            "<class 'pandas.core.series.Series'>\n",
            "59.60346345061239\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "3.9838316505409512\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "5.846810719713499\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.12060547610795497\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1905185274483507\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.2905848314522084\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08525813684036294\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6243510841596822\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.04946807710248732\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.25273485110673066\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.12526182546977893\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.14023296815900907\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1882269738327038\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.4265690596927336\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.2681734053598568\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "3.689159907910378\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "6.9474697924974045\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "5.127586258783875\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.7837736019650096\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.19831620446303624\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.7637494921528206\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4534962456927035\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08374647759979506\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08672262322749807\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0225935567359346\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1350271604195195\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0686684623139775\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "446.11810889868514\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "850.3237488418133\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "627.0453584431352\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.592128376024616\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "39.21744931756402\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "4.8054751864160465\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "19.143804201955447\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "8.059042284192268\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "16.735742748184478\n",
            "-------\n",
            "193\n",
            "<class 'pandas.core.series.Series'>\n",
            "8.74555707948718\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "404.34807843572065\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "721.843224529816\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "546.3587414010341\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "31.8550473694286\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "85.94800918628326\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "58.37532406928051\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "-9.667667306173119\n",
            "-------\n",
            "3265\n",
            "<class 'pandas.core.series.Series'>\n",
            "172396.36289240263\n",
            "-------\n",
            "7032\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.6279561179825712\n",
            "-------\n",
            "7032\n",
            "<class 'pandas.core.series.Series'>\n",
            "-6.566518116028376\n",
            "-------\n",
            "3155\n",
            "<class 'pandas.core.series.Series'>\n",
            "99.74270073247456\n",
            "-------\n",
            "16183\n",
            "<class 'pandas.core.series.Series'>\n",
            "48.12235719425693\n",
            "-------\n",
            "56450\n",
            "<class 'pandas.core.series.Series'>\n",
            "-345.66912966716797\n",
            "-------\n",
            "4592\n",
            "<class 'pandas.core.series.Series'>\n",
            "188.11369746654927\n",
            "-------\n",
            "4635\n",
            "<class 'pandas.core.series.Series'>\n",
            "354.85495010913627\n",
            "-------\n",
            "4685\n",
            "<class 'pandas.core.series.Series'>\n",
            "401.1337050612181\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.41042771696196817\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.23576721965165706\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.27179024188391077\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08201482150246397\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.06063273520671106\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.015716811496068916\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.302945491479517\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0012790129029831095\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6194259489147199\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00011285407967498025\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5145920325019749\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4840461949366136\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0012489184817364482\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9995561072866117\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9985253733589136\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0010156867170748223\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9983297596208103\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0012113004551781213\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9984200428845503\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0011210171914381372\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9987661287288869\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0007824549524131964\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.998427566489862\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0011210171914381372\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9986156566226536\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0009329270586465034\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0004438927133882556\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9999924763946884\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.52360531166535e-06\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.15001316630929543\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.8499868336907046\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.45600571794003686\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.44071775194673285\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.07956212617086107\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.023714403942369185\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4454877177143287\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.45123575217244105\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.10327653011323026\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5146070797125982\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.46165594552909756\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.02373697475830418\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5048263928074334\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4714366324342625\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.02373697475830418\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.41700334800436367\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5592822480532671\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.023714403942369185\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9260655306022646\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.05022006545536621\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.023714403942369185\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.21452055825151412\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.7617650378061167\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.023714403942369185\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5017718090508972\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.47451378700673363\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.023714403942369185\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5989617424669902\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.3760899823195275\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0249482752134823\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "7640321.80455911\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "88.81034157978446\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "9280.986128291217\n",
            "-------\n",
            "238\n",
            "<class 'pandas.core.series.Series'>\n",
            "359.1456678700361\n",
            "-------\n",
            "12\n",
            "<class 'pandas.core.series.Series'>\n",
            "171.56978595436053\n",
            "-------\n",
            "66\n",
            "<class 'pandas.core.series.Series'>\n",
            "183.80465694987558\n",
            "-------\n",
            "7433\n",
            "<class 'pandas.core.series.Series'>\n",
            "297.63680823680824\n",
            "-------\n",
            "7433\n",
            "<class 'pandas.core.series.Series'>\n",
            "85.07696267696268\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "57.265948047358194\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "74.59400954232197\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "26.089856865170525\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "26.10735112210638\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "20.427107262767272\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "36.555486835129884\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "33.4453083583672\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "38.1245803145432\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "31.6405725393179\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "27.96907580844672\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "14.846527655062731\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "15.284866731603648\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4885529921329444\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.7060903385485724\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.5711128789887739\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.020949350304958897\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.19066560594006896\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.07946610094581455\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.37134270308494655\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.40369486431538937\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.38804914699902765\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.09113409352072836\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.10607265977194379\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.09829399805533458\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0754883762043665\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0765491028020862\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0758419517369398\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.083974188986122\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0844161584018386\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.0843277645186953\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.104658357641651\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1072217802528066\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1057190842393707\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.328294881994166\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.3373110580747811\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.3343056660479096\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "37.85647017620902\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "50.238591682728625\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "44.182991930231495\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "2.4195907363143028\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "10.739024715040866\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "6.348765720963256\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "24.439494858072173\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "26.797064610167418\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "26.02149667946822\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "10.457744612255853\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "12.112477874730569\n",
            "-------\n",
            "5\n",
            "<class 'pandas.core.series.Series'>\n",
            "11.224472924673114\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4377485199257754\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.955641954581603\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.11865757548924112\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.287257593199327\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.5121756840520677\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.05487319961120438\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.288945833701511\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.022267385349474242\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.1423522134841389\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.11051093597803949\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.142034888869211\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.2578421843244676\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "2.986568878678095\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.674383670584077\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.2950428558805337\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.9709286913492976\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6995670230626491\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.19268573452581245\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08032164001060352\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.16391269771140762\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.10426791552531589\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.08651376959178252\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.09191534578942707\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.064416364760979\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.2330122824069982\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.1350181143412565\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "39.695224354892716\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "166.6789766848614\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "73.66072575295415\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "4.114884264648008\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "14.773304623076253\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.4545703493654492\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "9.137130300737663\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "7.596847090472641\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "12.082699077039427\n",
            "-------\n",
            "25\n",
            "<class 'pandas.core.series.Series'>\n",
            "9.763376765858975\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "23.77056065260748\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "133.72773468267152\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "50.85489858493763\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "11.101654169615728\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "17.410680001032926\n",
            "-------\n",
            "1\n",
            "<class 'pandas.core.series.Series'>\n",
            "12.905181408644754\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "-16.075631737056018\n",
            "-------\n",
            "96\n",
            "<class 'pandas.core.series.Series'>\n",
            "201522.56923899482\n",
            "-------\n",
            "336\n",
            "<class 'pandas.core.series.Series'>\n",
            "1.4737752686213805\n",
            "-------\n",
            "336\n",
            "<class 'pandas.core.series.Series'>\n",
            "-8.21398652340193\n",
            "-------\n",
            "100\n",
            "<class 'pandas.core.series.Series'>\n",
            "99.7756766273198\n",
            "-------\n",
            "730\n",
            "<class 'pandas.core.series.Series'>\n",
            "47.28919531545145\n",
            "-------\n",
            "7739\n",
            "<class 'pandas.core.series.Series'>\n",
            "-319.68147527242246\n",
            "-------\n",
            "272\n",
            "<class 'pandas.core.series.Series'>\n",
            "204.99139960166576\n",
            "-------\n",
            "280\n",
            "<class 'pandas.core.series.Series'>\n",
            "333.0601558253307\n",
            "-------\n",
            "287\n",
            "<class 'pandas.core.series.Series'>\n",
            "435.83800199437945\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6750309241915533\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.13880544265771338\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.12572892737232727\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.06043470577840608\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.021116805089238383\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.015638805442657715\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.3463509453967132\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0012369676621311187\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6156564764092596\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.591358897331684\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.40758084467220357\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0010602579961123874\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9995582258349531\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9826824527301643\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.01687577310478883\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9823290333981268\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.017229192436826295\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9824173882311362\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.01714083760381693\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9918713553631384\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.007156741473758614\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0005301289980561937\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9915179360311009\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.007510160805796077\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0005301289980561937\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9916062908641102\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0074218059727867115\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0005301289980561937\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00044177416504682807\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9999116451669906\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "8.835483300936562e-05\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.11212228308888496\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.8878777169111151\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6289097013606644\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.2680685633504153\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.09453967132002121\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0084820639688991\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6283795723626082\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.26859869234847145\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.10302173528892031\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6920834069623608\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.2990811097367026\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.008835483300936562\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6915532779643047\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.2996112387347588\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.008835483300936562\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.6843081816575367\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.30720975437356424\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0084820639688991\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.9699593567768157\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.02155857925428521\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0084820639688991\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.17847676267891854\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.8130411733521824\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0084820639688991\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.638717087824704\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.3528008482063969\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.0084820639688991\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.4907227425340166\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.49982329033398126\n",
            "-------\n",
            "0\n",
            "<class 'pandas.core.series.Series'>\n",
            "0.00945396713200212\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIC-iWYIr8Bh"
      },
      "source": [
        "###fill nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AelWge5nYDkO"
      },
      "source": [
        "normal = normal.fillna(value=values)\n",
        "fraud = fraud.fillna(value=fraud_values)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8198kder_SE"
      },
      "source": [
        "##Scale data with MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf9e2C1lasok"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "normal = sc.fit_transform(normal)\n",
        "fraud = sc.fit_transform(fraud)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bRaKbDsE0u"
      },
      "source": [
        "##Splite test data from normal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVoueDKcN3Rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a6b3f7b6-f46e-40d5-936b-a9f4da85b11b"
      },
      "source": [
        "X = normal[:120000]\n",
        "normal_test = normal[120000:]\n",
        "pd.DataFrame(X)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027642</td>\n",
              "      <td>0.201023</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.008195</td>\n",
              "      <td>0.103645</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>0.538636</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.042026</td>\n",
              "      <td>0.890779</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.129771</td>\n",
              "      <td>0.248175</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.001563</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>0.198954</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.016530</td>\n",
              "      <td>0.045413</td>\n",
              "      <td>0.910</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.919708</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119995</th>\n",
              "      <td>0.877656</td>\n",
              "      <td>0.020391</td>\n",
              "      <td>0.496264</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>0.277372</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119996</th>\n",
              "      <td>0.877664</td>\n",
              "      <td>0.004438</td>\n",
              "      <td>0.198954</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119997</th>\n",
              "      <td>0.877670</td>\n",
              "      <td>0.012978</td>\n",
              "      <td>0.461370</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>0.270073</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>0.877677</td>\n",
              "      <td>0.055424</td>\n",
              "      <td>0.544493</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.905109</td>\n",
              "      <td>0.236364</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>0.877686</td>\n",
              "      <td>0.015233</td>\n",
              "      <td>0.855656</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>0.277372</td>\n",
              "      <td>0.447288</td>\n",
              "      <td>0.823063</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000888</td>\n",
              "      <td>0.000888</td>\n",
              "      <td>0.000887</td>\n",
              "      <td>0.001201</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120000 rows  186 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2      3         4    ...  181  182  183  184  185\n",
              "0       0.000000  0.027642  0.201023  0.828  0.381679  ...  1.0  0.0  0.0  1.0  0.0\n",
              "1       0.000002  0.008195  0.103645  0.000  0.381679  ...  1.0  0.0  0.0  1.0  0.0\n",
              "2       0.000003  0.042026  0.890779  0.504  0.129771  ...  1.0  0.0  1.0  0.0  0.0\n",
              "3       0.000003  0.009026  0.198954  0.550  0.648855  ...  1.0  0.0  1.0  0.0  0.0\n",
              "4       0.000007  0.016530  0.045413  0.910  0.381679  ...  1.0  0.0  1.0  0.0  0.0\n",
              "...          ...       ...       ...    ...       ...  ...  ...  ...  ...  ...  ...\n",
              "119995  0.877656  0.020391  0.496264  0.060  0.648855  ...  0.0  0.0  1.0  0.0  0.0\n",
              "119996  0.877664  0.004438  0.198954  0.550  0.648855  ...  0.0  0.0  0.0  1.0  0.0\n",
              "119997  0.877670  0.012978  0.461370  0.890  0.648855  ...  0.0  0.0  0.0  1.0  0.0\n",
              "119998  0.877677  0.055424  0.544493  0.054  0.381679  ...  0.0  0.0  0.0  1.0  0.0\n",
              "119999  0.877686  0.015233  0.855656  0.890  0.648855  ...  0.0  0.0  0.0  1.0  0.0\n",
              "\n",
              "[120000 rows x 186 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4atYV5Td-R"
      },
      "source": [
        "# Auto Encoder Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jq6TFVqsOZ2"
      },
      "source": [
        "##Import libraris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTbz722KNOGA"
      },
      "source": [
        "from keras.models import Sequential , Model\n",
        "from keras.layers import Dense, Dropout,Input,BatchNormalization , Add\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXP-Qe6Wu5vB"
      },
      "source": [
        "##Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0qomHtpND6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4d632d-a6a9-48f0-f3e9-3c04a0a387f5"
      },
      "source": [
        "encoder_input = Input(186,name = 'input_encoder')\n",
        "encoder = Dense(128, activation='relu',name = 'encoder_layer1')(encoder_input)\n",
        "encoder = Dense(64, activation='relu',name = 'encoder_layer2')(encoder)\n",
        "encoder = BatchNormalization(name = 'encoder_layer3')(encoder)\n",
        "encoder = Dropout(0.2 , name = 'encoder_layer4')(encoder)\n",
        "encoder = Dense(512, activation='relu',name = 'encoder_layer5')(encoder)\n",
        "encoder = Dense(256, activation='relu',name = 'encoder_layer6')(encoder)\n",
        "encoder = Dense(256, activation='relu',name = 'encoder_layer7')(encoder)\n",
        "encoder = Dense(64, activation='relu',name = 'encoder_layer8')(encoder)\n",
        "encoder = BatchNormalization(name = 'encoder_layer9')(encoder)\n",
        "encoder = Dropout(0.2 , name = 'encoder_layer10')(encoder)\n",
        "encoder_output = Dense(10, activation='relu',name = 'output_encoder')(encoder)\n",
        "\n",
        "Encoder = Model(inputs= [encoder_input], outputs=[encoder_output],name = 'Encoder')\n",
        "Encoder.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_encoder (InputLayer)  [(None, 186)]             0         \n",
            "                                                                 \n",
            " encoder_layer1 (Dense)      (None, 128)               23936     \n",
            "                                                                 \n",
            " encoder_layer2 (Dense)      (None, 64)                8256      \n",
            "                                                                 \n",
            " encoder_layer3 (BatchNormal  (None, 64)               256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " encoder_layer4 (Dropout)    (None, 64)                0         \n",
            "                                                                 \n",
            " encoder_layer5 (Dense)      (None, 512)               33280     \n",
            "                                                                 \n",
            " encoder_layer6 (Dense)      (None, 256)               131328    \n",
            "                                                                 \n",
            " encoder_layer7 (Dense)      (None, 256)               65792     \n",
            "                                                                 \n",
            " encoder_layer8 (Dense)      (None, 64)                16448     \n",
            "                                                                 \n",
            " encoder_layer9 (BatchNormal  (None, 64)               256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " encoder_layer10 (Dropout)   (None, 64)                0         \n",
            "                                                                 \n",
            " output_encoder (Dense)      (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 280,202\n",
            "Trainable params: 279,946\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0CGHwfnsT08"
      },
      "source": [
        "##Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV9GY-XgNG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a374bdf-687a-4be8-8d35-fbf7d66efbb4"
      },
      "source": [
        "decoder_input = Input(10,name = 'input_decoder')\n",
        "decoder = Dense(128, activation='relu',name = 'decoder_layer1')(decoder_input)\n",
        "decoder = Dense(256, activation='relu',name = 'decoder_layer2')(decoder)\n",
        "decoder = BatchNormalization(name = 'decoder_layer3')(decoder)\n",
        "decoder = Dropout(0.2 , name = 'decoder_layer4')(decoder)\n",
        "decoder = Dense(512, activation='relu',name = 'decoder_layer5')(decoder)\n",
        "decoder = Dense(256, activation='relu',name = 'decoder_layer6')(decoder)\n",
        "decoder = Dense(128, activation='relu',name = 'decoder_layer7')(decoder)\n",
        "decoder = Dense(64, activation='relu',name = 'decoder_layer8')(decoder)\n",
        "decoder = BatchNormalization(name = 'decoder_layer9')(decoder)\n",
        "decoder = Dropout(0.2 , name = 'decoder_layer10')(decoder)\n",
        "decoder_output = Dense(186,activation = 'sigmoid',name ='output_layer')(decoder)\n",
        "\n",
        "Decoder = Model(inputs= [decoder_input], outputs=[decoder_output],name = 'Decoder')\n",
        "Decoder.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_decoder (InputLayer)  [(None, 10)]              0         \n",
            "                                                                 \n",
            " decoder_layer1 (Dense)      (None, 128)               1408      \n",
            "                                                                 \n",
            " decoder_layer2 (Dense)      (None, 256)               33024     \n",
            "                                                                 \n",
            " decoder_layer3 (BatchNormal  (None, 256)              1024      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " decoder_layer4 (Dropout)    (None, 256)               0         \n",
            "                                                                 \n",
            " decoder_layer5 (Dense)      (None, 512)               131584    \n",
            "                                                                 \n",
            " decoder_layer6 (Dense)      (None, 256)               131328    \n",
            "                                                                 \n",
            " decoder_layer7 (Dense)      (None, 128)               32896     \n",
            "                                                                 \n",
            " decoder_layer8 (Dense)      (None, 64)                8256      \n",
            "                                                                 \n",
            " decoder_layer9 (BatchNormal  (None, 64)               256       \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " decoder_layer10 (Dropout)   (None, 64)                0         \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 186)               12090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 351,866\n",
            "Trainable params: 351,226\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHKkJ52BsXip"
      },
      "source": [
        "##Auto Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOJ4_V7wNNCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b36748-b200-49e8-f7bf-34b52e9bfa7a"
      },
      "source": [
        "autoencoder_input = Input(186,name = 'input_autoencoder')\n",
        "latent = Encoder(autoencoder_input)\n",
        "decoded_data = Decoder(latent)\n",
        "autoencoder = Model(inputs= [autoencoder_input], outputs=[decoded_data],name = 'AutoEncoder')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"AutoEncoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_autoencoder (InputLay  [(None, 186)]            0         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " Encoder (Functional)        (None, 10)                280202    \n",
            "                                                                 \n",
            " Decoder (Functional)        (None, 186)               351866    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 632,068\n",
            "Trainable params: 631,172\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58UHhSrsee7"
      },
      "source": [
        "##Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpWz88VoNinM"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_93-JwslMm"
      },
      "source": [
        "##Create callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGc_F7pjOfbl"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "lrr= ReduceLROnPlateau(monitor='val_loss',\n",
        "                       factor=0.1, \n",
        "                       patience=3, \n",
        "                       min_lr=1e-9)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA8v-Y8Msou0"
      },
      "source": [
        "##Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MYQOoK-OXP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a985162-6bd3-4775-8ca9-9d44687cfdc5"
      },
      "source": [
        "history = autoencoder.fit(X, X,\n",
        "                    batch_size = 128,\n",
        "                    validation_split = 0.2,\n",
        "                              epochs= 50,\n",
        "                              callbacks=[lrr])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 11s 10ms/step - loss: 0.0454 - accuracy: 0.0175 - val_loss: 0.0156 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0130 - accuracy: 0.0040 - val_loss: 0.0102 - val_accuracy: 0.0203 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0106 - accuracy: 0.0053 - val_loss: 0.0094 - val_accuracy: 8.3333e-05 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0096 - accuracy: 0.0017 - val_loss: 0.0090 - val_accuracy: 2.0833e-04 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0090 - accuracy: 8.1250e-04 - val_loss: 0.0087 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0086 - accuracy: 3.4375e-04 - val_loss: 0.0084 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0083 - accuracy: 2.7083e-04 - val_loss: 0.0074 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0072 - accuracy: 2.9167e-04 - val_loss: 0.0060 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0066 - accuracy: 2.3958e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0062 - accuracy: 3.1250e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0059 - accuracy: 4.3750e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0057 - accuracy: 2.9167e-04 - val_loss: 0.0054 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0056 - accuracy: 3.7500e-04 - val_loss: 0.0053 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0054 - accuracy: 3.7500e-04 - val_loss: 0.0055 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0053 - accuracy: 3.6458e-04 - val_loss: 0.0054 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0050 - accuracy: 4.2708e-04 - val_loss: 0.0053 - val_accuracy: 8.3333e-05 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0049 - accuracy: 4.1667e-04 - val_loss: 0.0053 - val_accuracy: 4.1667e-05 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0049 - accuracy: 4.5833e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 3.9583e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.9375e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.7917e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.5833e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0048 - accuracy: 4.8958e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.9375e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 3.8542e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.5208e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.8958e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.6250e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 5.4167e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-08\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.1042e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-08\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.3750e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-08\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 6.4583e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 5.7292e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0048 - accuracy: 5.4167e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 4.3750e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 4.4792e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.7917e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 6.0417e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.0048 - accuracy: 5.6250e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 3.8542e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.0048 - accuracy: 5.6250e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0048 - accuracy: 5.6250e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.6875e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.5833e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0048 - accuracy: 5.2083e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.8958e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 5.2083e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.0048 - accuracy: 4.1667e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.6875e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.0048 - accuracy: 4.3750e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00 - lr: 1.0000e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DQRy6uvGs1"
      },
      "source": [
        "##Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE-MegdEudtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1daf5345-cb2b-4c06-d5af-587dfb59b1c0"
      },
      "source": [
        "autoencoder.save(\"./drive/MyDrive/Fraud Detection\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/Fraud Detection/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQspHr4osr7P"
      },
      "source": [
        "##Loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhGxcVbOxSp9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8e12fab6-60ad-4bac-86ba-729b8950e7f6"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "val_accuracy = history.history['val_loss']\n",
        "accuracval_accuracy = history.history['loss']\n",
        "plt.plot(val_accuracy)\n",
        "plt.plot(accuracval_accuracy)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('val_loss')\n",
        "plt.legend(['Val loss','Train loss'], loc='upper right')\n",
        "plt.savefig('plot_loss.png')\n",
        "plt.show()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2pkVllsw1j"
      },
      "source": [
        "#Finde Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmN8hXqas5jV"
      },
      "source": [
        "##Test Data loss value\n",
        "\n",
        "\n",
        "*   splite normal_test and fraud dataset into find_threshold_dataset and final_test\n",
        "\n",
        "*   give fraud and normal datasets to trained model and calculate loss value with categorical_crossentropy loss function\n",
        "\n",
        "*   plot loss values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTvYBe-z1QXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "583de006-c95f-4c4b-b700-36db14e7133e"
      },
      "source": [
        "from keras import losses\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "fin_th_normal = normal_test[:9000]\n",
        "predicted_x = autoencoder.predict(x=fin_th_normal)\n",
        "normal_loss = losses.categorical_crossentropy(predicted_x, fin_th_normal)\n",
        "print('normal loss mean:', np.mean(normal_loss))\n",
        "\n",
        "find_th_fraud = fraud[:9000]\n",
        "predicted_fraud_x = autoencoder.predict(x=find_th_fraud)\n",
        "fraud_loss = losses.categorical_crossentropy(predicted_fraud_x, find_th_fraud)\n",
        "print('fraud loss mean:', np.mean(fraud_loss))\n",
        "\n",
        "normal_x = []\n",
        "normal_y = []\n",
        "fraud_x = []\n",
        "fraud_y = []\n",
        "\n",
        "for i in range(len(normal_loss)):\n",
        "  normal_x.append(i)\n",
        "  normal_y.append(normal_loss[i])\n",
        "for i in range(len(fraud_loss)):\n",
        "  fraud_x.append(i)\n",
        "  fraud_y.append(fraud_loss[i])\n",
        "plt.scatter(normal_x, normal_y, label='normal')\n",
        "plt.scatter(fraud_x, fraud_y, label='fraud')\n",
        "plt.legend(['normal','fraud'], loc='upper right')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal loss mean: 138.47027889405237\n",
            "fraud loss mean: 158.68006371159564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f961966d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_763n4EM8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f238842-1f92-4da7-c238-e1edde489e6c"
      },
      "source": [
        "final_test_normal = normal_test[9000:]\n",
        "final_test_fraud= fraud[9000:]\n",
        "print(final_test_normal.shape)\n",
        "print(final_test_fraud.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3915, 186)\n",
            "(2318, 186)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ5NJx9Vt1gc"
      },
      "source": [
        "##Find threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-3VGwQWJg2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a421db3-58bb-46d3-ef48-05bcf5948d71"
      },
      "source": [
        "min = np.min(normal_y)\n",
        "max = np.max(fraud_y)\n",
        "print(max)\n",
        "max_th = 0\n",
        "th = 0\n",
        "min = int(min)\n",
        "max = int(max+1)\n",
        "print(min, max)\n",
        "for i in range(min, max):\n",
        "  print(i)\n",
        "  bad = 0\n",
        "  good = 0\n",
        "  for j in normal_y:\n",
        "    if j < i:\n",
        "      good += 1\n",
        "    else:\n",
        "      bad += 1\n",
        "  for j in fraud_y:\n",
        "    if j > i:\n",
        "      good += 1\n",
        "    else:\n",
        "      bad += 1\n",
        "  print(good, bad)\n",
        "  score = good / (good + bad)\n",
        "  if score > max_th:\n",
        "    max_th = score\n",
        "    th = i\n",
        "\n",
        "print('th:', th)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321.01801642586514\n",
            "126 322\n",
            "126\n",
            "9000 9000\n",
            "127\n",
            "9002 8998\n",
            "128\n",
            "9125 8875\n",
            "129\n",
            "9626 8374\n",
            "130\n",
            "10267 7733\n",
            "131\n",
            "10841 7159\n",
            "132\n",
            "11469 6531\n",
            "133\n",
            "12855 5145\n",
            "134\n",
            "13720 4280\n",
            "135\n",
            "14852 3148\n",
            "136\n",
            "15402 2598\n",
            "137\n",
            "15656 2344\n",
            "138\n",
            "15753 2247\n",
            "139\n",
            "15835 2165\n",
            "140\n",
            "15893 2107\n",
            "141\n",
            "15940 2060\n",
            "142\n",
            "15987 2013\n",
            "143\n",
            "16073 1927\n",
            "144\n",
            "16143 1857\n",
            "145\n",
            "16236 1764\n",
            "146\n",
            "16315 1685\n",
            "147\n",
            "16365 1635\n",
            "148\n",
            "16412 1588\n",
            "149\n",
            "16417 1583\n",
            "150\n",
            "16419 1581\n",
            "151\n",
            "16404 1596\n",
            "152\n",
            "16308 1692\n",
            "153\n",
            "16073 1927\n",
            "154\n",
            "15711 2289\n",
            "155\n",
            "15229 2771\n",
            "156\n",
            "14790 3210\n",
            "157\n",
            "13800 4200\n",
            "158\n",
            "13112 4888\n",
            "159\n",
            "12087 5913\n",
            "160\n",
            "10622 7378\n",
            "161\n",
            "9889 8111\n",
            "162\n",
            "9347 8653\n",
            "163\n",
            "9186 8814\n",
            "164\n",
            "9060 8940\n",
            "165\n",
            "8997 9003\n",
            "166\n",
            "8911 9089\n",
            "167\n",
            "8857 9143\n",
            "168\n",
            "8846 9154\n",
            "169\n",
            "8809 9191\n",
            "170\n",
            "8792 9208\n",
            "171\n",
            "8755 9245\n",
            "172\n",
            "8768 9232\n",
            "173\n",
            "8768 9232\n",
            "174\n",
            "8825 9175\n",
            "175\n",
            "8838 9162\n",
            "176\n",
            "8837 9163\n",
            "177\n",
            "8824 9176\n",
            "178\n",
            "8836 9164\n",
            "179\n",
            "8844 9156\n",
            "180\n",
            "8871 9129\n",
            "181\n",
            "8907 9093\n",
            "182\n",
            "8934 9066\n",
            "183\n",
            "8971 9029\n",
            "184\n",
            "9035 8965\n",
            "185\n",
            "9085 8915\n",
            "186\n",
            "9099 8901\n",
            "187\n",
            "9100 8900\n",
            "188\n",
            "9096 8904\n",
            "189\n",
            "9090 8910\n",
            "190\n",
            "9082 8918\n",
            "191\n",
            "9079 8921\n",
            "192\n",
            "9076 8924\n",
            "193\n",
            "9074 8926\n",
            "194\n",
            "9073 8927\n",
            "195\n",
            "9069 8931\n",
            "196\n",
            "9067 8933\n",
            "197\n",
            "9066 8934\n",
            "198\n",
            "9066 8934\n",
            "199\n",
            "9065 8935\n",
            "200\n",
            "9065 8935\n",
            "201\n",
            "9064 8936\n",
            "202\n",
            "9064 8936\n",
            "203\n",
            "9064 8936\n",
            "204\n",
            "9064 8936\n",
            "205\n",
            "9064 8936\n",
            "206\n",
            "9062 8938\n",
            "207\n",
            "9059 8941\n",
            "208\n",
            "9059 8941\n",
            "209\n",
            "9054 8946\n",
            "210\n",
            "9051 8949\n",
            "211\n",
            "9041 8959\n",
            "212\n",
            "9035 8965\n",
            "213\n",
            "9029 8971\n",
            "214\n",
            "9023 8977\n",
            "215\n",
            "9020 8980\n",
            "216\n",
            "9016 8984\n",
            "217\n",
            "9016 8984\n",
            "218\n",
            "9015 8985\n",
            "219\n",
            "9013 8987\n",
            "220\n",
            "9011 8989\n",
            "221\n",
            "9010 8990\n",
            "222\n",
            "9007 8993\n",
            "223\n",
            "9008 8992\n",
            "224\n",
            "9008 8992\n",
            "225\n",
            "9007 8993\n",
            "226\n",
            "9007 8993\n",
            "227\n",
            "9004 8996\n",
            "228\n",
            "9003 8997\n",
            "229\n",
            "9003 8997\n",
            "230\n",
            "9003 8997\n",
            "231\n",
            "9003 8997\n",
            "232\n",
            "9003 8997\n",
            "233\n",
            "9003 8997\n",
            "234\n",
            "9002 8998\n",
            "235\n",
            "9002 8998\n",
            "236\n",
            "9002 8998\n",
            "237\n",
            "9002 8998\n",
            "238\n",
            "9002 8998\n",
            "239\n",
            "9002 8998\n",
            "240\n",
            "9002 8998\n",
            "241\n",
            "9002 8998\n",
            "242\n",
            "9002 8998\n",
            "243\n",
            "9002 8998\n",
            "244\n",
            "9002 8998\n",
            "245\n",
            "9002 8998\n",
            "246\n",
            "9002 8998\n",
            "247\n",
            "9002 8998\n",
            "248\n",
            "9002 8998\n",
            "249\n",
            "9002 8998\n",
            "250\n",
            "9002 8998\n",
            "251\n",
            "9002 8998\n",
            "252\n",
            "9002 8998\n",
            "253\n",
            "9002 8998\n",
            "254\n",
            "9002 8998\n",
            "255\n",
            "9002 8998\n",
            "256\n",
            "9002 8998\n",
            "257\n",
            "9002 8998\n",
            "258\n",
            "9002 8998\n",
            "259\n",
            "9002 8998\n",
            "260\n",
            "9002 8998\n",
            "261\n",
            "9002 8998\n",
            "262\n",
            "9002 8998\n",
            "263\n",
            "9002 8998\n",
            "264\n",
            "9002 8998\n",
            "265\n",
            "9002 8998\n",
            "266\n",
            "9002 8998\n",
            "267\n",
            "9002 8998\n",
            "268\n",
            "9002 8998\n",
            "269\n",
            "9002 8998\n",
            "270\n",
            "9002 8998\n",
            "271\n",
            "9002 8998\n",
            "272\n",
            "9002 8998\n",
            "273\n",
            "9002 8998\n",
            "274\n",
            "9002 8998\n",
            "275\n",
            "9002 8998\n",
            "276\n",
            "9002 8998\n",
            "277\n",
            "9002 8998\n",
            "278\n",
            "9002 8998\n",
            "279\n",
            "9002 8998\n",
            "280\n",
            "9002 8998\n",
            "281\n",
            "9002 8998\n",
            "282\n",
            "9002 8998\n",
            "283\n",
            "9002 8998\n",
            "284\n",
            "9002 8998\n",
            "285\n",
            "9002 8998\n",
            "286\n",
            "9002 8998\n",
            "287\n",
            "9002 8998\n",
            "288\n",
            "9002 8998\n",
            "289\n",
            "9002 8998\n",
            "290\n",
            "9002 8998\n",
            "291\n",
            "9002 8998\n",
            "292\n",
            "9002 8998\n",
            "293\n",
            "9002 8998\n",
            "294\n",
            "9002 8998\n",
            "295\n",
            "9002 8998\n",
            "296\n",
            "9002 8998\n",
            "297\n",
            "9002 8998\n",
            "298\n",
            "9002 8998\n",
            "299\n",
            "9002 8998\n",
            "300\n",
            "9002 8998\n",
            "301\n",
            "9002 8998\n",
            "302\n",
            "9002 8998\n",
            "303\n",
            "9002 8998\n",
            "304\n",
            "9002 8998\n",
            "305\n",
            "9002 8998\n",
            "306\n",
            "9002 8998\n",
            "307\n",
            "9002 8998\n",
            "308\n",
            "9002 8998\n",
            "309\n",
            "9002 8998\n",
            "310\n",
            "9002 8998\n",
            "311\n",
            "9002 8998\n",
            "312\n",
            "9002 8998\n",
            "313\n",
            "9002 8998\n",
            "314\n",
            "9002 8998\n",
            "315\n",
            "9002 8998\n",
            "316\n",
            "9002 8998\n",
            "317\n",
            "9002 8998\n",
            "318\n",
            "9001 8999\n",
            "319\n",
            "9001 8999\n",
            "320\n",
            "9001 8999\n",
            "321\n",
            "9001 8999\n",
            "th: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDQ228JpuGV_"
      },
      "source": [
        "##Final test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PNi5ZVfQsfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f298ae-6dcc-433b-cace-7ada05577d8d"
      },
      "source": [
        "predicted_x = autoencoder.predict(x=final_test_normal)\n",
        "normal_loss = losses.categorical_crossentropy(predicted_x, final_test_normal)\n",
        "print('normal loss mean:', np.mean(normal_loss))\n",
        "\n",
        "predicted_fraud_x = autoencoder.predict(x=final_test_fraud)\n",
        "fraud_loss = losses.categorical_crossentropy(predicted_fraud_x, final_test_fraud)\n",
        "print('fraud loss mean:', np.mean(fraud_loss))\n",
        "\n",
        "right = 0\n",
        "wrong = 0\n",
        "for i in normal_loss:\n",
        "  if i < 150:\n",
        "    right += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "  \n",
        "for i in fraud_loss:\n",
        "  if i > 150:\n",
        "    right += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "print(right)\n",
        "print(wrong + right)\n",
        "\n",
        "print('Final Accuracy:', right / (right + wrong))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal loss mean: 133.90568594584119\n",
            "fraud loss mean: 159.24645146511344\n",
            "6096\n",
            "6233\n",
            "Final Accuracy: 0.9780202149847586\n"
          ]
        }
      ]
    }
  ]
}